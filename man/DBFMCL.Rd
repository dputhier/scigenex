% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dbfmcl_main.R
\name{DBFMCL}
\alias{DBFMCL}
\title{The "Density Based Filtering and Markov CLustering" algorithm (DBF-MCL).}
\usage{
DBFMCL(
  data = NULL,
  filename = NULL,
  path = ".",
  name = NULL,
  distance_method = c("pearson", "spearman", "euclidean"),
  av_dot_prod_min = 2,
  min_cluster_size = 10,
  silent = FALSE,
  k = 50,
  random = 3,
  memory_used = 1024,
  fdr = 10,
  inflation = 8,
  set.seed = 123
)
}
\arguments{
\item{data}{a \code{matrix}, \code{data.frame} or \code{Seurat} object.}

\item{filename}{a character string representing the file name.}

\item{path}{a character string representing the data directory where
intermediary files are to be stored. Default to current working directory.}

\item{name}{a prefix for the names of the intermediary files created by DBF
and MCL.}

\item{distance_method}{a method to compute the distance to the k-th nearest
neighbor. One of "pearson" (Pearson's correlation coefficient-based
distance), "spearman" (Spearman's rho-based distance), "euclidean".}

\item{av_dot_prod_min}{Any cluster with average dot product below this value is discarded. This allow to delete
clusters in which correlation is influenced/supported by very few samples (typically 1).}

\item{min_cluster_size}{Minimum number of element inside a cluster. MCL tend to create lots of clusters with
very few (e.g 2) objects.}

\item{silent}{if set to TRUE, the progression of distance matrix calculation
is not displayed.}

\item{k}{the neighborhood size.}

\item{random}{the number of simulated distributions S to compute. By default
\code{random = 3}.}

\item{memory_used}{size of the memory used to store part of the distance
matrix. The subsequent sub-matrix is used to computed simulated distances to
the k-th nearest neighbor (see detail section).}

\item{fdr}{an integer value corresponding to the false discovery rate
(range: 0 to 100).}

\item{inflation}{the main control of MCL. Inflation affects cluster
granularity. It is usually chosen somewhere in the range \code{[1.2-5.0]}.
\code{inflation = 5.0} will tend to result in fine-grained clusterings, and
whereas \code{inflation = 1.2} will tend to result in very coarse grained
clusterings. By default, \code{inflation = 2.0}. Default setting gives very
good results for microarray data when k is set between 70 and 250.}

\item{set.seed}{specify seeds for random number generator.}
}
\value{
a ClusterSets class object.
}
\description{
DBFMCL is a tree-steps adaptative algorithm that \emph{(i)} find elements
located in dense areas (DBF), \emph{(ii)} uses selected items to construct a
graph, \emph{(iii)} performs graph partitioning using the Markov CLustering
Algorithm (MCL).

This function requires installation of the mcl program
(\url{http://www.micans.org/mcl}). See "Warnings" section for more
informations.

When analyzing a noisy dataset, one is interested in isolating dense regions
as they are populated with genes/elements that display weak distances to
their nearest neighbors (i.e. strong profile similarities). To isolate these
regions DBF-MCL computes, for each gene/element, the distance with its kth
nearest neighbor (DKNN).In order to define a critical DKNN value that will
depend on the dataset and below which a gene/element will be considered as
falling in a dense area, DBF-MCL computes simulated DKNN values by using an
empirical randomization procedure. Given a dataset containing n genes and p
samples, a simulated DKNN value is obtained by sampling n distance values
from the gene-gene distance matrix D and by extracting the kth-smallest
value. This procedure is repeated n times to obtain a set of simulated DKNN
values S. Computed distributions of simulated DKNN are used to compute a FDR
value for each observed DKNN value. The critical value of DKNN is the one
for which a user-defined FDR value (typically 10\%) is observed. Genes with
DKNN value below this threshold are selected and used to construct a graph.
In this graph, edges are constructed between two genes (nodes) if one of
them belongs to the k-nearest neighbors of the other. Edges are weighted
based on the respective coefficient of correlation (\emph{i.e.}, similarity)
and the graph obtained is partitioned using the Markov CLustering Algorithm
(MCL).
}
\section{Warnings}{
 With the current implementation, this function only works
only on UNIX-like plateforms.

MCL should be installed. One can used the following command lines in a
terminal:

\code{# Download the latest version of mcl (the script has been tested
successfully with the 06-058 version).}
\code{wget http://micans.org/mcl/src/mcl-latest.tar.gz}
\code{# Uncompress and install mcl}
\code{tar xvfz mcl-latest.tar.gz}
\code{cd mcl-xx-xxx}
\code{./configure}
\code{make}
\code{sudo make install}
\code{# You should get mcl in your path}
\code{mcl -h}
}

\examples{

\dontrun{
  m <- matrix(rnorm(80000), nc=20)
  m[1:100,1:10] <- m[1:100,1:10] + 4
   m[101:200,11:20] <- m[101:200,11:20] + 3
   m[201:300,5:15] <- m[201:300,5:15] + -2
   res <- DBFMCL(data=m,
                 distance_method="pearson",
                av_dot_prod_min = 0,
                inflation = 1.2,
                 k=25,
                fdr = 10)
plot_clust(res, ceil = 10, floor = -10)
plot_clust(res, type="tile", ceil = 10, floor = -10)
write_clust(res, filename_out = "ALL.sign.txt")
}

}
\references{
Van Dongen S. (2000) A cluster algorithm for graphs. National
Research Institute for Mathematics and Computer Science in the 1386-3681.
}
\author{
Bergon A., Bavais J., Textoris J., Granjeaud S., Lopez F and Puthier
D.
}
\keyword{manip}
